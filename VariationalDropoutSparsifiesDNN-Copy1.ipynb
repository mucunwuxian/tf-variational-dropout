{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]    = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# simple mnist experiment\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# import variational_dropout as vd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(x, \n",
    "                    phase, \n",
    "                    n_hidden, \n",
    "                    activation_fn=tf.nn.relu, \n",
    "                    thresh=3,\n",
    "                    initializer=tf.contrib.layers.xavier_initializer, \n",
    "                    scope=None):\n",
    "\n",
    "    # you get xavier initialization, and that's it for now\n",
    "    n_input     = int(x.shape[1])\n",
    "    print('n_input = %s' % n_input)\n",
    "    w           = tf.get_variable(name=\"w\", \n",
    "                                  shape=[n_input, n_hidden], \n",
    "                                  initializer=initializer())\n",
    "    b           = tf.get_variable(name=\"b\", \n",
    "                                  shape=[n_hidden,], \n",
    "                                  initializer=tf.constant_initializer(0.))\n",
    "\n",
    "    ard_init    = -10.\n",
    "    log_sigma2  = tf.get_variable(name=\"log_sigma2\", \n",
    "                                  shape=[n_input, n_hidden], \n",
    "                                  initializer=tf.constant_initializer(ard_init))\n",
    "    \n",
    "    eps         = 1e-8\n",
    "    log_alpha   = tf.clip_by_value(t=(log_sigma2 - tf.log(tf.square(w) + eps)),\n",
    "                                   clip_value_min=-8., \n",
    "                                   clip_value_max=8., \n",
    "                                   name='log_alpha')\n",
    "    # log_alpha   = tf.identity(log_alpha, name='log_alpha') # <- not need...\n",
    "\n",
    "    # at test time,we just mask\n",
    "    select_mask = tf.cast(x=tf.less(x=log_alpha, y=thresh), \n",
    "                          dtype=tf.float32)\n",
    "    fc_masked   = tf.matmul(a=x, b=(w * select_mask))\n",
    "\n",
    "    # choose between adding noise, or applying mask, depending on phase\n",
    "    mu          = tf.matmul(a=x, b=w)\n",
    "    si          = tf.sqrt(x=tf.matmul(a=tf.square(x), b=(tf.exp(log_alpha) * tf.square(w))) + eps)\n",
    "    fc_noisy    = mu + (si * tf.random_normal(shape=tf.shape(mu), \n",
    "                                              mean=0.0,\n",
    "                                              stddev=1.0))\n",
    "\n",
    "    activations = tf.cond(pred=phase, true_fn=(lambda:fc_noisy), false_fn=(lambda:fc_masked))\n",
    "    \n",
    "    return activation_fn(activations + b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def conv2d(x, \n",
    "#            phase, \n",
    "#            n_filters, \n",
    "#            kernel_size, \n",
    "#            activation_fn=tf.nn.relu,\n",
    "#            strides=[1,1,1,1],\n",
    "#            initializer=tf.contrib.layers.xavier_initializer_conv2d, \n",
    "#            thresh=3,\n",
    "#            padding='SAME', \n",
    "#            scope=None, \n",
    "#            bias=False):\n",
    "    \n",
    "#     n_input_channels = int(x.shape[3])\n",
    "#     # define parameters\n",
    "#     conv_param_shape = kernel_size + [n_input_channels, n_filters]\n",
    "#     w                = tf.get_variable(\"w\", conv_param_shape, initializer=initializer())\n",
    "    \n",
    "#     if (bias):\n",
    "#         b = tf.get_variable(\"b\", [n_filters], initializer=tf.constant_initializer())\n",
    "\n",
    "#     # homemade initializers\n",
    "#     ard_init      = -10.\n",
    "#     log_sigma2    = tf.get_variable(\"log_sigma2\", shape=conv_param_shape, initializer=tf.constant_initializer(ard_init))\n",
    "    \n",
    "#     eps           = 1e-8\n",
    "#     log_alpha     = tf.clip_by_value((log_sigma2 - tf.log(tf.square(w) + eps)), -8., 8.)\n",
    "#     log_alpha     = tf.identity(log_alpha, name='log_alpha')\n",
    "\n",
    "#     select_mask   = tf.cast(tf.less(log_alpha, thresh), tf.float32)\n",
    "\n",
    "#     conved_mu     = tf.nn.conv2d(x, w, strides=strides, padding=padding)\n",
    "#     conved_si     = tf.sqrt(tf.nn.conv2d(tf.square(x),\n",
    "#                                          tf.exp(log_alpha)*tf.square(w),\n",
    "#                                          strides=strides, \n",
    "#                                          padding=padding)+1e-8)\n",
    "#     conv2d_noisy  = conved_mu + tf.random_normal(tf.shape(conved_mu))*conved_si\n",
    "    \n",
    "#     conv2d_masked = tf.nn.conv2d(x, w*select_mask, strides=strides, padding=padding)\n",
    "    \n",
    "#     activations   = tf.cond(phase, lambda: conv2d_noisy, lambda: conv2d_masked)\n",
    "#     if bias:\n",
    "#         return activation_fn(activations + b)\n",
    "#     else:\n",
    "#         return activation_fn(activations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepnn(x, phase):\n",
    "    \"\"\"\n",
    "    Builds the network graph.\n",
    "\n",
    "    Args:\n",
    "        x: an input tensor with the dimensions (N_examples, 784), where 784 is the\n",
    "        number of pixels in a standard MNIST image.\n",
    "        x: True is train, False is test\n",
    "\n",
    "    Returns:\n",
    "        A tuple (y, log_alphas). y is a tensor of shape (N_examples, 10), with values\n",
    "        equal to the logits of classifying the digit into one of 10 classes (the\n",
    "        digits 0-9). log_alphas is a list of the log_alpha parameters describing\n",
    "        the effective dropout rate of the approximate posterior.\n",
    "    \"\"\"\n",
    "    \n",
    "#     # Reshape to use within a convolutional neural net.\n",
    "#     # Last dimension is for \"features\" - there is only one here, since images are\n",
    "#     # grayscale -- it would be 3 for an RGB image, 4 for RGBA, etc.\n",
    "#     with tf.variable_scope('reshape', reuse=tf.AUTO_REUSE):\n",
    "#         x_image      = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "#     # First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "#     with tf.variable_scope('conv1', reuse=tf.AUTO_REUSE):\n",
    "#         h_conv1      = conv2d(x_image, phase, 32, [5,5])\n",
    "    \n",
    "#     # Pooling layer - downsamples by 2X.\n",
    "#     with tf.variable_scope('pool1', reuse=tf.AUTO_REUSE):\n",
    "#         # max_pool_2x2 downsamples a feature map by 2X.\n",
    "#         h_pool1      = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "#     # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "#     with tf.variable_scope('conv2', reuse=tf.AUTO_REUSE):\n",
    "#         h_conv2      = conv2d(h_pool1, phase, 64, [5,5])\n",
    "\n",
    "#     # Second pooling layer.\n",
    "#     with tf.variable_scope('pool2', reuse=tf.AUTO_REUSE):\n",
    "#         # max_pool_2x2 downsamples a feature map by 2X.\n",
    "#         h_pool2      = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "#     # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n",
    "#     # is down to 7x7x64 feature maps -- maps this to 1024 features.\n",
    "#     with tf.variable_scope('fc1', reuse=tf.AUTO_REUSE):\n",
    "#         h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "#         h_fc1        = fully_connected(h_pool2_flat, phase, 1024)\n",
    "\n",
    "    # \n",
    "    with tf.variable_scope('fc1', reuse=tf.AUTO_REUSE):\n",
    "        h_fc1        = fully_connected(x=x, phase=phase, n_hidden=20)\n",
    "\n",
    "    # Map the 1024 features to 10 classes, one for each digit\n",
    "    with tf.variable_scope('fc2', reuse=tf.AUTO_REUSE):\n",
    "        y_conv       = fully_connected(h_fc1, phase, 10) \n",
    "    \n",
    "    return y_conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "x     = tf.placeholder(tf.float32, [None, 784])\n",
    "y_    = tf.placeholder(tf.float32, [None, 10])\n",
    "phase = tf.placeholder(tf.bool, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_input = 784\n",
      "n_input = 20\n"
     ]
    }
   ],
   "source": [
    "# Build the graph for the deep net\n",
    "y_conv = deepnn(x, phase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-c02f4aebd60c>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/envs/develop_36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/envs/develop_36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/envs/develop_36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/envs/develop_36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/envs/develop_36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-79e6ed33a197>:14: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with tf.name_scope('loss'):\n",
    "#     # cross entropy part of the ELBO\n",
    "#     cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,\n",
    "#                                                         logits=y_conv))\n",
    "#     # prior DKL part of the ELBO\n",
    "#     log_alphas = gather_logalphas(tf.get_default_graph())\n",
    "#     divergences = [dkl_qp(la) for la in log_alphas]\n",
    "#     # combine to form the ELBO\n",
    "#     N = float(mnist.train.images.shape[0])\n",
    "#     dkl = tf.reduce_sum(tf.stack(divergences))\n",
    "#     elbo = cross_entropy+(1./N)*dkl\n",
    "\n",
    "# cross entropy part of the ELBO\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "\n",
    "# prior DKL part of the ELBO\n",
    "# utility to gather variational dropout parameters\n",
    "node_defs     = [n for n in tf.get_default_graph().as_graph_def().node if 'log_alpha' in n.name]\n",
    "tensors       = [tf.get_default_graph().get_tensor_by_name(n.name+\":0\") for n in node_defs]\n",
    "log_alphas    = tensors\n",
    "\n",
    "k1, k2, k3    = 0.63576, 1.8732, 1.48695\n",
    "C             = -k1\n",
    "\n",
    "divergences   = []\n",
    "for la in log_alphas:\n",
    "    mdkl      = k1 * tf.nn.sigmoid(k2 + k3 * la) - 0.5 * tf.log1p(tf.exp(-la)) + C\n",
    "    dkl_qp    = -tf.reduce_sum(mdkl)\n",
    "\n",
    "    divergences.append(dkl_qp)\n",
    "\n",
    "# combine to form the ELBO\n",
    "N             = float(mnist.train.images.shape[0])\n",
    "dkl           = tf.reduce_sum(tf.stack(divergences))\n",
    "elbo          = cross_entropy + (1. / N) * dkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f98b3fd5f698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivergences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "sess.run(divergences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'fc1/log_alpha/Minimum/y:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc1/log_alpha/Minimum:0' shape=(784, 20) dtype=float32>,\n",
       " <tf.Tensor 'fc1/log_alpha/y:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc1/log_alpha:0' shape=(784, 20) dtype=float32>,\n",
       " <tf.Tensor 'fc2/log_alpha/Minimum/y:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc2/log_alpha/Minimum:0' shape=(20, 10) dtype=float32>,\n",
       " <tf.Tensor 'fc2/log_alpha/y:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'fc2/log_alpha:0' shape=(20, 10) dtype=float32>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(log_alphas[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(elbo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "accuracy           = tf.reduce_mean(correct_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handy function to keep track of sparsity\n",
    "thresh   = 3\n",
    "N_active = 0.\n",
    "N_total  = 0.\n",
    "for la in log_alphas:\n",
    "    m         = tf.cast(tf.less(la, thresh), tf.float32)\n",
    "    n_active  = tf.reduce_sum(m)\n",
    "    n_total   = tf.cast(tf.reduce_prod(tf.shape(m)), tf.float32)\n",
    "    N_active += n_active\n",
    "    N_total  += n_total\n",
    "sparse = 1.0 - N_active / N_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1, training loss: 3.57332\n",
      "step 0, val accuracy 0.1, val loss: 2.32837, sparsity: 0.019456\n",
      "step 1000, training accuracy 0.88, training loss: 0.577377\n",
      "step 1000, val accuracy 0.9, val loss: 0.443237, sparsity: 0.677056\n",
      "step 2000, training accuracy 0.9, training loss: 0.573867\n",
      "step 2000, val accuracy 0.92, val loss: 0.251329, sparsity: 0.690593\n",
      "step 3000, training accuracy 0.9, training loss: 0.528345\n",
      "step 3000, val accuracy 0.96, val loss: 0.224894, sparsity: 0.674852\n",
      "step 4000, training accuracy 0.96, training loss: 0.320257\n",
      "step 4000, val accuracy 0.88, val loss: 0.283596, sparsity: 0.681526\n",
      "step 5000, training accuracy 0.96, training loss: 0.365582\n",
      "step 5000, val accuracy 0.86, val loss: 0.302795, sparsity: 0.682471\n",
      "step 6000, training accuracy 0.94, training loss: 0.277568\n",
      "step 6000, val accuracy 0.94, val loss: 0.220547, sparsity: 0.667044\n",
      "step 7000, training accuracy 0.96, training loss: 0.283287\n",
      "step 7000, val accuracy 0.98, val loss: 0.119686, sparsity: 0.691915\n",
      "step 8000, training accuracy 0.96, training loss: 0.30925\n",
      "step 8000, val accuracy 0.98, val loss: 0.122064, sparsity: 0.687067\n",
      "step 9000, training accuracy 0.92, training loss: 0.344386\n",
      "step 9000, val accuracy 0.94, val loss: 0.157733, sparsity: 0.677811\n",
      "step 10000, training accuracy 0.94, training loss: 0.375033\n",
      "step 10000, val accuracy 0.92, val loss: 0.279041, sparsity: 0.670696\n",
      "step 11000, training accuracy 0.98, training loss: 0.243402\n",
      "step 11000, val accuracy 0.94, val loss: 0.224003, sparsity: 0.669248\n",
      "step 12000, training accuracy 0.96, training loss: 0.273651\n",
      "step 12000, val accuracy 0.94, val loss: 0.14325, sparsity: 0.672019\n",
      "step 13000, training accuracy 0.9, training loss: 0.401027\n",
      "step 13000, val accuracy 0.96, val loss: 0.245683, sparsity: 0.675104\n",
      "step 14000, training accuracy 0.92, training loss: 0.30295\n",
      "step 14000, val accuracy 0.98, val loss: 0.190233, sparsity: 0.671767\n",
      "step 15000, training accuracy 0.92, training loss: 0.370696\n",
      "step 15000, val accuracy 0.98, val loss: 0.0800508, sparsity: 0.668682\n",
      "step 16000, training accuracy 0.88, training loss: 0.389168\n",
      "step 16000, val accuracy 0.96, val loss: 0.183913, sparsity: 0.65867\n",
      "step 17000, training accuracy 0.9, training loss: 0.424657\n",
      "step 17000, val accuracy 0.94, val loss: 0.158612, sparsity: 0.672019\n",
      "step 18000, training accuracy 0.96, training loss: 0.198409\n",
      "step 18000, val accuracy 1, val loss: 0.0382765, sparsity: 0.666289\n",
      "step 19000, training accuracy 0.96, training loss: 0.274352\n",
      "step 19000, val accuracy 0.94, val loss: 0.337898, sparsity: 0.662007\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7498e8222067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'step %d, val accuracy %g, val loss: %g, sparsity: %g'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/develop_36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m     \"\"\"\n\u001b[0;32m-> 2399\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/develop_36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5246\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5247\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5248\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/develop_36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/develop_36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/develop_36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/develop_36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/develop_36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/develop_36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(10000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i % 1000 == 0:\n",
    "        train_accuracy, train_loss = sess.run((accuracy, elbo), feed_dict={x: batch[0], y_: batch[1], phase: False})\n",
    "        print('step %d, training accuracy %g, training loss: %g' % (i, train_accuracy, train_loss))\n",
    "        val_x, val_y = mnist.validation.next_batch(50)\n",
    "        val_accuracy, val_loss, val_sp = sess.run((accuracy, cross_entropy, sparse), feed_dict={x: val_x, y_: val_y, phase: False})\n",
    "        print('step %d, val accuracy %g, val loss: %g, sparsity: %g' % (i, val_accuracy, val_loss, val_sp))\n",
    "    train_step.run(session=sess, feed_dict={x: batch[0], y_: batch[1], phase: True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test accuracy %g' % accuracy.eval(session=sess, feed_dict={x: mnist.test.images, y_: mnist.test.labels, phase: False}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_sparse = 0.1\n",
    "\n",
    "w_1_tmp = sess.run(tf.trainable_variables('fc1/w:0'))[0].ravel()\n",
    "w_2_tmp = sess.run(tf.trainable_variables('fc2/w:0'))[0].ravel()\n",
    "\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig = plt.figure(figsize=(12,8),dpi=100)\n",
    "\n",
    "ax  = plt.subplot(2, 2, 1)\n",
    "plt.hist(w_1_tmp, bins=50, log=True)\n",
    "\n",
    "ax  = plt.subplot(2, 2, 2)\n",
    "plt.hist(w_2_tmp, bins=50, log=True)\n",
    "\n",
    "ax  = plt.subplot(2, 2, 3)\n",
    "plt.plot(np.sort(w_1_tmp))\n",
    "\n",
    "ax  = plt.subplot(2, 2, 4)\n",
    "plt.plot(np.sort(w_2_tmp))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(np.sum(np.abs(w_1_tmp) <= threshold_sparse) / len(w_1_tmp))\n",
    "print(np.sum(np.abs(w_2_tmp) <= threshold_sparse) / len(w_2_tmp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1 = sess.run(tf.trainable_variables('fc1/w:0'))[0]\n",
    "w_1[np.abs(w_1) < threshold_sparse] = 0\n",
    "w_2 = sess.run(tf.trainable_variables('fc2/w:0'))[0]\n",
    "w_2[np.abs(w_2) < threshold_sparse] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tf.trainable_variables('fc1/w:0')\n",
    "tmp[0].load(w_1, sess)\n",
    "tmp = tf.trainable_variables('fc2/w:0')\n",
    "tmp[0].load(w_2, sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1_tmp = sess.run(tf.trainable_variables('fc1/w:0'))[0].ravel()\n",
    "w_2_tmp = sess.run(tf.trainable_variables('fc2/w:0'))[0].ravel()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,8),dpi=100)\n",
    "\n",
    "ax  = plt.subplot(2, 2, 1)\n",
    "plt.hist(w_1_tmp, bins=50, log=True)\n",
    "\n",
    "ax  = plt.subplot(2, 2, 2)\n",
    "plt.hist(w_2_tmp, bins=50, log=True)\n",
    "\n",
    "ax  = plt.subplot(2, 2, 3)\n",
    "plt.plot(np.sort(w_1_tmp))\n",
    "\n",
    "ax  = plt.subplot(2, 2, 4)\n",
    "plt.plot(np.sort(w_2_tmp))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(np.sum(np.abs(w_1_tmp) == 0) / len(w_1_tmp))\n",
    "print(np.sum(np.abs(w_2_tmp) == 0) / len(w_2_tmp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test accuracy %g' % accuracy.eval(session=sess, feed_dict={x: mnist.test.images, y_: mnist.test.labels, phase: False}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
